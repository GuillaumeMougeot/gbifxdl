# gbifxdl

GBIF eXtreme downloader (gbifxdl) is a Python tool meant for scraping large 
datasets of images using [GBIF](https://www.gbif.org/) website. 

![](https://github.com/GuillaumeMougeot/gbifxdl/blob/main/docs/assets/gbifxdl_workflow.drawio.svg)

gbifxdl is a two-steps process:
* The first step takes as input a GBIF predicate (see [GBIF documentation](https://techdocs.gbif.org/en/data-use/api-downloads) and the exemple
[here](https://github.com/GuillaumeMougeot/gbifxdl/blob/main/examples/payload_template.json))
and outputs a download link towards an occurrence datasets, generated by GBIF and stored in a Darwin Core Archive format. This step requires a [GBIF account](https://www.gbif.org/user/profile). The duration of creation of the occurrence file by GBIF website can take a few minutes to a few hours. If properly configured, GBIF should notify the user once the file is ready for download.
* If the download is completed, which can be seen [here](https://www.gbif.org/user/download), the second step takes the previous download link as input, download the occurrence file, download the images and postprocess the file.

> Warning: this package is still under active development and may undergo major updates in the future.

## Introduction in video

[![](https://github.com/GuillaumeMougeot/gbifxdl/blob/main/docs/assets/miniature.png)](https://youtu.be/rN_9kxXmYXw)


## Installation

Source installation only for now.

### To get the code and the GBIF templates:
```
git clone git@github.com:GuillaumeMougeot/gbifxdl.git
cd gbifxdl
pip install -e .
```

### Or in one line (mostly for CLI users):

```bash
pip install git+https://github.com/GuillaumeMougeot/gbifxdl.git
```

### Or Step-by-step:
* Install [Python version >= 3.10](https://www.python.org/downloads/) language or use [Anaconda](https://www.anaconda.com/download).
* [Download gbifxdl repository](https://github.com/GuillaumeMougeot/gbifxdl/archive/refs/heads/main.zip) or [git](https://git-scm.com/) clone it `git clone git@github.com:GuillaumeMougeot/gbifxdl.git`. Unzip the downloaded .zip if needed.
* Open a terminal/a command prompt where Python can be executed (check that by running `python` command in that terminal) and navigate to the folder of download (with `cd` command) `cd gbifxdl`.
* (Optional) Create a virtual environment with either `python -m venv venv-name` or `conda create -n venv-name`.
* Run `pip install -e .` command (don't forget the `.` at the end of the command). 

## Usage

The package provides an Application Programming Interface (API) and a minimal Command Line Interface (CLI).

**Requirements:** To use gbifxdl you **must** create an account on [GBIF website](https://www.gbif.org/user/profile) using an email address and **not** using other connection systems such as "Connect with Google, GitHub or ORCID". This email and username and password will be used when requesting data from GBIF. 

### Step 0: Write a GBIF predicate

[GBIF predicate](https://techdocs.gbif.org/en/data-use/api-downloads) are small JSON files describing the data you want from GBIF. Here is a minimal example that could be called `my_payload.json`:

```json
{
    "creator": "your_username",
    "notificationAddresses": [
        "your.email@domain.tld"
    ],
    "format": "DWCA",
    "predicate": {
        "type": "and",
        "predicates": [
            {
                "type": "in",
                "key": "TAXON_KEY",
                "values": [
                    "7017", "5343"
                ]
            },
            {
                "type": "equals",
                "key": "MEDIA_TYPE",
                "value": "StillImage"
            },
        ]
    }
}
```

This payload file request GBIF for all images (`StillImage`) of Nymphalidae (`7017`) and Tortricidae (`5343`) families.

To use the above example:
- Save it in a `choose_a_name.json` file
- Edit the `creator` field with your GBIF username and the `notificationAddresses` with your email address.
- You can go to the next step to post this request to GBIF.

To learn more about predicate:
- More examples are stored in [usecases folder](https://github.com/GuillaumeMougeot/gbifxdl/tree/main/usecases) of this repo. For example, [payload_DEMO.json](https://github.com/GuillaumeMougeot/gbifxdl/blob/main/usecases/payload_DEMO.json) show you how to limit the country and year of the image or to choose the "basis of record" which can be important if you do not want preserved specimens but only living specimens.
- Check-out the GBIF API documentation about predicates: [GBIF predicate](https://techdocs.gbif.org/en/data-use/api-downloads).
- Here is the exhaustive of all possible predicate keys: [here](https://gbif.github.io/gbif-api/apidocs/org/gbif/api/model/occurrence/search/OccurrenceSearchParameter.html).

> Note: if you don't have a predicate yet but you have a list of species or genus or family or any other taxa, you could use this [online lookup tool](https://www.gbif.org/tools/species-lookup) to get a list of GBIF ids. Then you could look at [the payload/predicate template](https://github.com/GuillaumeMougeot/gbifxdl/blob/main/examples/payload_template.json) and edit the list of values under the "TAXON_KEY" field.

### Step 1: Post your request to GBIF with GBIFXDL
**For the first step, post your [GBIF predicate](https://techdocs.gbif.org/en/data-use/api-downloads) with the following command:**

```bash
gbifpost -p payload_DEMO.json -k key.txt --password mysecret
```
Arguments:
--payload, -p : Path to the payload JSON file
--keyfile, -k : Path to save the download key (default: download_key.txt)
--password, -w : GBIF password. If not given, it will be read from .env (GBIF_PWD).

**Or using the API:**

```python
from gbifxdl import post

payload_path = "payload_traits.json"
pwd = "your_gbif_password"
download_key = post(payload_path, pwd=pwd, wait=False)

# Eventually save the download key to a local file.
download_key_path = "download_key.txt"
with open(download_key_path, "w") as file:
    file.write(download_key)
```

### Step 2: preprocess, download and postprocess your images

**Run the entire GBIFXDL pipeline with this command:**
```bash
gbifpipe -d data/gbifxdl/mydataset -k download_key.txt 
```

Arguments:
--dataset, -d : Path to the dataset directory
--keyfile, -k : Path to the download key file (default: download_key.txt)

**...or do this step by step with the API:**

For the second step, download the occurrences file with:
```python
from gbifxdl import poll_status, download_occurrences

download_key_path = "download_key.txt"

# Poll the POST status and wait if not ready to be downloaded
status = poll_status(download_key)

# Download the GBIF file
if status == 'succeeded':
    download_path = download_occurrences(
        download_key= download_key,
        dataset_dir = dataset_dir,
        file_format = 'dwca'
    )
else:
    print(f"Download failed because status is {status}.")
    download_path = None
    exit()
```

Preprocess the occurrence file and download the images with:
```python
from gbifxdl import preprocess_occurrences_stream, AsyncImagePipeline

download_path = "path/to/occurrence_file"
images_dir = "path/to/output/folder"

# Preprocess the occurrence file
preprocessed_path = preprocess_occurrences_stream(
    dwca_path=download_path,
    max_img_spc=500, # Maximum number of images per species
    )

# Define an asynchronous routine to download image in parallel
downloader = AsyncImagePipeline(
    parquet_path=preprocessed_path,
    output_dir=images_dir,
)
downloader.run()
images_metadata_path = downloader.metadata_file
```

Postprocess the images and their metadata with:
```python
from gbifxdl import postprocess

images_metadata_path = "path/to/metadata.parquet"
images_dir = "path/to/output/folder"

postprocess(
    parquet_path=images_metadata_path,
    img_dir=images_dir,
)
```

The scripts above are used in practice in the [usecases folder](https://github.com/GuillaumeMougeot/gbifxdl/tree/main/usecases).

For more detailed examples, look at the [examples folder](https://github.com/GuillaumeMougeot/gbifxdl/tree/main/examples).

## Contributing

This repo welcomes external contributions!

If you find an issue, feel free to open it [here](https://github.com/GuillaumeMougeot/gbifxdl/issues).

If you would like to contribute to the code, feel free to send a pull request. Currently, most of the code of this package is stored in a single script in `gbifxdl/src/gbifxdl.py`.

For any other request, don't hesitate to reach out by sending me an email.

Many thanks to anyone interested by this work.

## TODO

* [x] Integrate resizing in the pipeline.
* [ ] Deep learning processing during postprocessing.
* [ ] CLI
 
## Acknowledgement

This work has been inspired by the amazing works done in [gbif-dl](https://github.com/plantnet/gbif-dl/tree/master) and in [ami-ml](https://github.com/RolnickLab/ami-ml/tree/main/src/dataset_tools).








